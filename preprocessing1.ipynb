{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a10247",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "91a10247",
        "outputId": "50f44b9c-7605-49d3-9cff-4d98a4fbe398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 2️⃣ Imports\n",
        "# ==========================\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0VK22UJywGHp"
      },
      "id": "0VK22UJywGHp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_universe_dataset_with_labels(base_path):\n",
        "    all_data = []\n",
        "\n",
        "    for participant in os.listdir(base_path):\n",
        "        participant_path = os.path.join(base_path, participant)\n",
        "        if not os.path.isdir(participant_path):\n",
        "            continue\n",
        "\n",
        "        for session in [\"Lab1\", \"Lab2\", \"Wild\"]:\n",
        "            session_path = os.path.join(participant_path, session)\n",
        "            if not os.path.exists(session_path):\n",
        "                continue\n",
        "\n",
        "            # Load labels if exist\n",
        "            label_file = os.path.join(session_path, \"Task_Labels.csv\")\n",
        "            if os.path.exists(label_file):\n",
        "                labels = pd.read_csv(label_file)\n",
        "            else:\n",
        "                labels = None\n",
        "\n",
        "            features_path = os.path.join(session_path, \"Features\")\n",
        "            if not os.path.exists(features_path):\n",
        "                continue\n",
        "\n",
        "            for task in os.listdir(features_path):\n",
        "                task_path = os.path.join(features_path, task)\n",
        "                if not os.path.isdir(task_path):\n",
        "                    continue\n",
        "\n",
        "                for file in os.listdir(task_path):\n",
        "                    if file.endswith(\".pickle\"):\n",
        "                        file_path = os.path.join(task_path, file)\n",
        "                        try:\n",
        "                            df = pd.read_pickle(file_path)\n",
        "\n",
        "                            # Add metadata\n",
        "                            df[\"participant\"] = participant\n",
        "                            df[\"session\"] = session\n",
        "                            df[\"task\"] = task\n",
        "                            df[\"feature_type\"] = file.replace(\".pickle\", \"\")\n",
        "\n",
        "                            # Merge labels if available\n",
        "                            if labels is not None:\n",
        "                                # Merge on trial_id if exists, otherwise just append\n",
        "                                if 'trial_id' in df.columns and 'trial_id' in labels.columns:\n",
        "                                    df = df.merge(labels, on='trial_id', how='left')\n",
        "                                else:\n",
        "                                    df = pd.concat([df.reset_index(drop=True), labels.reset_index(drop=True)], axis=1)\n",
        "\n",
        "                            all_data.append(df)\n",
        "\n",
        "                        except Exception as e:\n",
        "                            print(\"Error reading:\", file_path, e)\n",
        "\n",
        "    if not all_data:\n",
        "        raise ValueError(\"No data found!\")\n",
        "\n",
        "    dataset = pd.concat(all_data, ignore_index=True)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "mZyLHWpEvquE"
      },
      "id": "mZyLHWpEvquE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BASE_PATH = \"/content/drive/MyDrive/universe/UNIVERSE\"  # change to your path\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/universe/UNIVERSE\"\n",
        "BASE_PATH2 = \"/content/drive/MyDrive/universe/UNIVERSE/UN_101\"\n",
        "BASE_PATH3 = \"/content/drive/MyDrive/universe/UNIVERSE/UN_101/Lab1\"\n",
        "BASE_PATH4 = \"/content/drive/MyDrive/universe/UNIVERSE/UN_101/Lab1/Features\"\n",
        "BASE_PATH5 = \"/content/drive/MyDrive/universe/UNIVERSE/UN_101/Lab1/Features/arithmetix_easy\"\n",
        "\n",
        "print(\"BASE FOLDER CONTENT:\")\n",
        "print(os.listdir(BASE_PATH))\n",
        "print(os.listdir(BASE_PATH2))\n",
        "print(os.listdir(BASE_PATH3))\n",
        "print(os.listdir(BASE_PATH4))\n",
        "print(os.listdir(BASE_PATH5))\n",
        "# dataset = load_universe_dataset(BASE_PATH)\n",
        "# dataset.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yqNWt1DvtQ2",
        "outputId": "8bc2e348-a11e-4161-ba83-296604ff3c50"
      },
      "id": "6yqNWt1DvtQ2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASE FOLDER CONTENT:\n",
            "['UN_101', 'UN_104', 'UN_105', 'UN_107', 'UN_103', 'UN_106', 'UN_112', 'UN_110', 'UN_109', 'UN_108', 'UN_111', 'UN_102']\n",
            "['Lab1', 'Lab2', 'Wild']\n",
            "['Labeled', 'Raw', 'Lab_Notes.pdf', 'Preprocessed', 'Features', 'Task_Labels.csv']\n",
            "['relaxation_video', 'arithmetix_easy', 'n_back_easy', 'stroop_easy', 'sudoku_easy', 'arithmetix_hard', 'n_back_hard', 'stroop_hard', 'sudoku_hard']\n",
            "['EEG_features.pickle', 'HRV_features.pickle', 'EDA_features.pickle', 'TEMP_features.pickle']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/universe/UNIVERSE\"\n",
        "\n",
        "# Load dataset with labels\n",
        "dataset = load_universe_dataset_with_labels(BASE_PATH)\n",
        "\n",
        "# Now check columns\n",
        "print(dataset.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6q5uH_l2DHq",
        "outputId": "4e0a51e5-2511-46a1-8a59-9b58ab1d869c"
      },
      "id": "b6q5uH_l2DHq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['mean_δ', 'mean_θ', 'mean_α', 'mean_β', 'mean_γ', 'α/θ', 'θ/α',\n",
            "       'frontal_α_asy', 'δ_asy', 'θ_asy', 'α_asy', 'β_asy', 'γ_asy',\n",
            "       'participant', 'session', 'task', 'feature_type', 'Task',\n",
            "       'Mental Demand', 'Physical Demand', 'Temporal Demand', 'Performance',\n",
            "       'Effort', 'Frustration', 'physical_demand__vs__temporal_demand',\n",
            "       'performance__vs__effort', 'mental_demand__vs__physical_demand',\n",
            "       'effort__vs__frustration', 'physical_demand__vs__performance',\n",
            "       'mental_demand__vs__effort', 'performance__vs__frustration',\n",
            "       'physical_demand__vs__effort', 'mental_demand__vs__performance',\n",
            "       'temporal_demand__vs__performance', 'physical_demand__vs__frustration',\n",
            "       'temporal_demand__vs__effort', 'mental_demand__vs__frustration',\n",
            "       'mental_demand__vs__temporal_demand',\n",
            "       'temporal_demand__vs__frustration', 'Weighted Nasa Score', 'HRV_MeanNN',\n",
            "       'HRV_SDNN', 'HRV_RMSSD', 'HRV_LFn', 'HRV_HFn', 'HRV_ratio_LFn_HFn',\n",
            "       'SCR_Peaks_N', 'SCR_Peaks_Amplitude_Mean', 'mean_temp', 'std_temp',\n",
            "       'Mental stress level', 'Mental effort level', 'Recording number:',\n",
            "       'Labeled folder names', 'Date', 'Questionnaire timestamp',\n",
            "       'Recording started', 'Recording ended', 'Tasks performed',\n",
            "       'Break Taken', 'Additional information ', 'Effort vs Performance',\n",
            "       'Physical Demand vs Mental Demand', 'Frustration vs Temporal Demand',\n",
            "       'Effort vs Temporal Demand', 'Frustration vs Physical Demand',\n",
            "       'Effort vs Physical Demand', 'Performance vs Frustration',\n",
            "       'Temporal Demand vs Physical Demand', 'Performance vs Physical Demand',\n",
            "       'Frustration vs Mental Demand', 'Temporal Demand vs Mental Demand',\n",
            "       'Effort vs Frustration', 'Performance vs Mental Demand',\n",
            "       'Effort vs Mental Demand', 'Performance vs Temporal Demand',\n",
            "       'Raw folder names', 'Unnamed: 33', 'Unnamed: 34', 'Unnamed: 35'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.rename(columns={\n",
        "    \"Weighted Nasa Score\": \"fatigue\",\n",
        "    \"Mental stress level\": \"stress\",\n",
        "    \"Mental effort level\": \"focus\"\n",
        "})\n"
      ],
      "metadata": {
        "id": "6jdIU_kM7gxq"
      },
      "id": "6jdIU_kM7gxq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ml_columns = [\n",
        "    # EEG features\n",
        "    'mean_δ','mean_θ','mean_α','mean_β','mean_γ',\n",
        "    'α/θ','θ/α','frontal_α_asy','δ_asy','θ_asy','α_asy','β_asy','γ_asy',\n",
        "    # HRV\n",
        "    'HRV_MeanNN','HRV_SDNN','HRV_RMSSD','HRV_LFn','HRV_HFn','HRV_ratio_LFn_HFn',\n",
        "    # EDA/SCR\n",
        "    'SCR_Peaks_N','SCR_Peaks_Amplitude_Mean',\n",
        "    # Temperature\n",
        "    'mean_temp','std_temp',\n",
        "    # NASA TLX main scores\n",
        "    'Mental Demand','Physical Demand','Temporal Demand','Performance','Effort','Frustration',\n",
        "    # Labels\n",
        "    'fatigue','stress','focus',\n",
        "]\n",
        "\n",
        "# Drop all other columns\n",
        "dataset = dataset[[c for c in ml_columns if c in dataset.columns]]"
      ],
      "metadata": {
        "id": "cuOldPFr-7Wf"
      },
      "id": "cuOldPFr-7Wf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 2️⃣ Clean & preprocess the dataset\n",
        "# ==========================\n",
        "def clean_dataset(df, label_columns=[\"fatigue\", \"stress\", \"focus\"]):\n",
        "    # 1. Fill missing values only for numeric columns\n",
        "    numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
        "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
        "\n",
        "    # 2. Encode categorical columns\n",
        "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
        "        if col not in [\"participant\", \"session\", \"task\", \"feature_type\"]:\n",
        "            le = LabelEncoder()\n",
        "            df[col] = le.fit_transform(df[col].astype(str))\n",
        "\n",
        "    # 3. Standardize numeric features\n",
        "    numeric_cols = [c for c in numeric_cols if c not in label_columns]\n",
        "    scaler = StandardScaler()\n",
        "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "    return df, scaler"
      ],
      "metadata": {
        "id": "oCSj7ZPOwIXX"
      },
      "id": "oCSj7ZPOwIXX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 3️⃣ Split into train/test\n",
        "# ==========================\n",
        "def prepare_and_save_train_test(df, label_columns=[\"fatigue\", \"stress\", \"focus\"], base_folder=\"/content/drive/MyDrive/universe_ml\", test_size=0.2):\n",
        "    # Create folder structure\n",
        "    os.makedirs(base_folder, exist_ok=True)\n",
        "    os.makedirs(os.path.join(base_folder, \"train\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(base_folder, \"test\"), exist_ok=True)\n",
        "\n",
        "    X = df.drop(columns=label_columns)\n",
        "    y = df[label_columns]\n",
        "\n",
        "    # Stratify on fatigue label for balanced split (can be changed)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=42,\n",
        "        stratify=y[label_columns[0]] if label_columns[0] in y else None\n",
        "    )\n",
        "\n",
        "    # Combine features + labels and save as CSV\n",
        "    train_df = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
        "    test_df = pd.concat([X_test.reset_index(drop=True), y_test.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    train_path = os.path.join(base_folder, \"train\", \"train_dataset.csv\")\n",
        "    test_path = os.path.join(base_folder, \"test\", \"test_dataset.csv\")\n",
        "\n",
        "    train_df.to_csv(train_path, index=False)\n",
        "    test_df.to_csv(test_path, index=False)\n",
        "\n",
        "    print(\"✅ Train/Test datasets saved:\")\n",
        "    print(\"Train:\", train_path)\n",
        "    print(\"Test:\", test_path)\n",
        "\n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "id": "7ZpGhM32wVJD"
      },
      "id": "7ZpGhM32wVJD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 4️⃣ Run preprocessing pipeline\n",
        "# ==========================\n",
        "# Clean the dataset\n",
        "cleaned_dataset, scaler = clean_dataset(dataset)\n",
        "\n",
        "# Split into train/test and save\n",
        "train_df, test_df = prepare_and_save_train_test(cleaned_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-zAmPmb5bB3",
        "outputId": "f67fe4a6-226e-45da-eeb6-70d3fe6dd443"
      },
      "id": "X-zAmPmb5bB3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train/Test datasets saved:\n",
            "Train: /content/drive/MyDrive/universe_ml/train/train_dataset.csv\n",
            "Test: /content/drive/MyDrive/universe_ml/test/test_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgcwP8hN9bZT",
        "outputId": "5514578c-9665-476b-c99b-fb9d6afd5006"
      },
      "id": "OgcwP8hN9bZT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mean_δ', 'mean_θ', 'mean_α', 'mean_β', 'mean_γ', 'α/θ', 'θ/α', 'frontal_α_asy', 'δ_asy', 'θ_asy', 'α_asy', 'β_asy', 'γ_asy', 'HRV_MeanNN', 'HRV_SDNN', 'HRV_RMSSD', 'HRV_LFn', 'HRV_HFn', 'HRV_ratio_LFn_HFn', 'SCR_Peaks_N', 'SCR_Peaks_Amplitude_Mean', 'mean_temp', 'std_temp', 'Mental Demand', 'Physical Demand', 'Temporal Demand', 'Performance', 'Effort', 'Frustration', 'fatigue', 'stress', 'focus']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}